1. Dataset
- Какой датасет выбран: S06-hw-dataset-01.csv
- Размер: 12000 строк на 30 столбцов
- Целевая переменная: 0 = 0.676583; 1 = 0.323417
- Признаки: вещественные
2. Protocol
- Разбиение: train/test Размер обучающей выборки: (9000, 28); Размер тестовой выборки: (3000, 28)
- Подбор: CV на train (сколько фолдов, что оптимизировали) 5‑fold CV; средняя метрика на CV (scoring) — ROC‑AUC для бинарных задач; аккуратный перебор (Pipeline + cross_val_score)
- Метрики: accuracy для dt = 0.856667, bg = 0.921667, rf = 0.933000, gb = 0.906333, F1 для dt = 0.776739, bg = 0.873859, rf = 0.891644, gb = 0.844666, ROC-AUC для dt = 00.834335, bg = 0.962678, rf = 0.970335, gb = 0.958239
3. Models
Опишите, какие модели сравнивали и какие гиперпараметры подбирали.
- DummyClassifier (baseline) - most_frequent
- LogisticRegression (baseline из S05) - использовался Pipeline со StandardScaler. При необходимости выполнен подбор C через CV (перебор C_values = [0.01, 0.1, 1.0, 10.0])
- DecisionTreeClassifier (контроль сложности: max_depth + min_samples_leaf или ccp_alpha) - контроль сложности: max_depth и min_samples_leaf
- RandomForestClassifier - основной ансамбль; подбирались/исследовались: n_estimators, max_depth, max_features (например sqrt), min_samples_leaf
- Один boosting (AdaBoost / GradientBoosting / HistGradientBoosting) - выбран GradientBoostingClassifier
4. Results
- Таблица/список финальных метрик на test по всем моделям - accuracy для dt = 0.856667, bg = 0.921667, rf = 0.933000, gb = 0.906333, F1 для dt = 0.776739, bg = 0.873859, rf = 0.891644, gb = 0.844666, ROC-AUC для dt = 00.834335, bg = 0.962678, rf = 0.970335, gb = 0.958239
- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение - Random Forest; Random Forest показывает наилучшее качество ранжирования (ROC‑AUC) и высокую accuracy; ансамблевый подход уменьшает дисперсию по сравнению с одиночным деревом и даёт более стабильные предсказания.
5. Analysis
- Устойчивость: что будет, если поменять random_state (хотя бы 5 прогонов для 1-2 моделей) – кратко - для RandomForest разброс метрик обычно невелик (малое std), что указывает на устойчивость; для одиночного DecisionTree разброс может быть больше.
- Ошибки: confusion matrix для лучшей модели + комментарий - ![alt text](image.png) В зависимости от задачи (стоимость ошибок) можно менять порог предсказания или оптимизировать по F1/precision/recall
- Интерпретация: permutation importance (top-10/15) + выводы - ![alt text](image-1.png) Наибольшее влияние оказывают num19 и num18 — их перемешивание приводит к наибольшему падению ROC‑AUC, значит модель активно использует эти признаки для разделения классов
6. Conclusion
- 3-6 коротких тезисов: что вы поняли про деревья/ансамбли и про честный ML-протокол. - 1. Ансамблевые методы (Random Forest, Bagging, Gradient Boosting) существенно превосходят одиночное дерево по стабильности и качеству (в данном эксперименте Random Forest показал наилучший ROC‑AUC).; 2. Контроль сложности одиночного дерева (max_depth, min_samples_leaf или ccp_alpha) необходим для борьбы с переобучением, но ансамбли лучше справляются с дисперсией; 3. Подбор гиперпараметров через CV на train и финальная оценка на test — обязательный элемент честного ML‑протокола; тест используется только один раз для финальной оценки.